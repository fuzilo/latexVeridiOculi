\subsection*{TECNOLOGIAS }

Para a criação de uma base de dados documental capaz de comportar uma grande variedade de dados não estruturados, utilizaremos o MongoDB, um banco de dados não relacional. Uma das principais características do MongoDB é a escalabilidade, já que bancos NoSQL são projetados para escalarem horizontalmente, distribuindo-se por clusters de hardware.\cite{AWSNoSQL}

A fim de interagir com esses dados de forma dinâmica, optou-se pelo desenvolvimento de um sistema web em JavaScript, uma linguagem amplamente utilizada, orientada a objetos e compatível com diversas plataformas. Sua principal função é tornar as páginas web mais interativas, possibilitando a criação de elementos como animações complexas, botões interativos e menus pop-up.\cite{MDSJavaScript}

No desenvolvimento da aplicação web, utilizamos o framework Flask, uma ferramenta voltada para a criação de aplicações web com a linguagem Python. A escolha deste framework se deve à facilidade de integração com algoritmos de IA para identificação de imagens, importados diretamente de bibliotecas Python.\cite{flask-docs}

Para organizar e orientar o desenvolvimento do projeto, utilizamos o framework SCRUM. Segundo Costa et. al \textcite{costa2022metodologias}, existem diversas metodologias para a gestão de projetos e programação de software, sendo o SCRUM uma das mais comumente empregadas. Essa metodologia reduz atrasos em projetos e aumenta a satisfação dos clientes em comparação com métodos tradicionais de desenvolvimento de software.

\subsection*{IMPLEMENTAÇÃO DO ALGORITMO TENSORFLOW}

Para a implementação do algoritmo de identificação de espécies de árvores, foi criado um dataset, um conjunto de dados organizados de contendo 90 imagens da classe Embaúba, capturadas pelos próprios autores durante o mês de março de 2024. Adicionalmente, foram utilizadas 310 imagens obtidas da internet para compor uma segunda classe de árvores genéricas, com o objetivo de validar o modelo.

Neste estudo, utilizamos uma rede neural totalmente conectada (Fully Connected Neural Network) para classificar as imagens em diferentes categorias. A fim de verificar como o modelo generaliza para dados novos, ou seja, como ele se comporta com dados que não foram usados durante o treinamento, utilizou-se a validação cruzada(K-Fold Cross Validation). Neste método, os dados são divididos em K partes iguais, posteriormente ele é treinado K vezes, e a cada iteração é utilizado uma dessas partes como conjuntos de teste até completar todos. A métrica de desempenho é calculada para cada uma das K execuções e ao final é feita a média desse valores. \cite{tensorflow_training_loop_from_scratch}
O procedimento de avaliação do modelo envolve validação cruzada  com 10 folds, visando garantir a robustez e a capacidade de generalização do modelo. O dataset é dividido em 10 partes, e o modelo é treinado e validado 10 vezes, utilizando, a cada rodada, uma parte distinta para validação enquanto as outras nove são usadas para treinamento.

A arquitetura da rede neural é composta por uma camada de entrada que achata a imagem (de tamanho 170 \texttimes 170 pixels) em um vetor, seguida por duas camadas densas (Fully Connected Layers) com 512 e 256 unidades, respectivamente, ambas usando a função de ativação ReLU. Esta função mantém valores positivos inalterados e “zera” todos os valores negativos, criando um gráfico com uma linha reta que segue o eixo horizontal (para valores negativos) e outra linha reta que segue uma inclinação positiva (para valores positivos).\cite{tensorflow_relu_activation}

A camada de saída utiliza a função de ativação softmax para prever a classe da imagem entre as possíveis categorias. O modelo é compilado com o otimizador Adam e treinado utilizando a função de perda sparse\_categorical\_crossentropy, apropriada para tarefas de classificação multiclasses com rótulos inteiros. A entropia cruzada calcula o erro comparando as probabilidades atribuídas pelo modelo a cada classe (saída) com as probabilidades reais (valores desejados), normalmente representadas por "1" para a classe correta e "0" para as demais. O objetivo é minimizar essa perda para que o modelo faça previsões mais precisas.\cite{tensorflow_sparse_categorical_crossentropy}

Com intuito de garantir que a rede neural seja confiável, seu aprendizado deve ser refinado gradualmente. Para tanto, o conjunto de dados é treinado várias vezes, denominando-se épocas, ou epoch em inglês. Durante o treinamento, são realizadas 100 épocas para assegurar que o modelo tenha tempo suficiente para aprender as características dos dados, com batch size definido como 32. A métrica de desempenho adotada é a acurácia, que mede a proporção de previsões corretas do modelo. Os valores de acurácia para cada fold são coletados, e a acurácia média é calculada para avaliar o desempenho geral do modelo.\cite{tensorflow_training_loop_from_scratch}

\subsection*{IMPLEMENTAÇÃO DE APLICAÇÃO MOBILE PARA VISUALIZAÇÃO DE RELATÓRIOS}
Para o desenvolvimento de um sistema de visualização de relatórios de identificação de árvores em ambiente mobile, a aplicação será construída em React Native, proporcionando uma interface intuitiva e responsiva. Esta interface permitirá que os usuários naveguem pelos relatórios, utilizando filtros específicos por espécie, localização e outras características relevantes. Além disso, será implementada uma função de atualização em tempo real, garantindo que as informações mais recentes processadas pela API sejam refletidas nos relatórios.

A API será desenvolvida em Flask (Python) e hospedada em um ambiente de nuvem AWS, com dados armazenados em um bucket S3. Esse setup em nuvem garantirá escalabilidade e alta disponibilidade, além de segurança no controle de acesso às informações. A API acessará e retornará os dados de inventário florestal conforme solicitado pelo aplicativo mobile, após realizar testes de conectividade e otimizações de desempenho para melhor integração entre API e aplicação.

Para validar a funcionalidade da inteligência artificial generativa utilizada na identificação das espécies arbóreas, serão realizados testes de precisão e eficiência, utilizando conjuntos de dados de teste e métodos de benchmarking. A IA será avaliada quanto à sua capacidade de identificar corretamente espécies nativas e invasoras. Por fim, testes de integração garantirão que os relatórios gerados pela IA estejam formatados adequadamente para visualização no sistema mobile, assegurando a consistência e confiabilidade dos dados apresentados aos usuários.